{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional, Add, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from attention import AttentionLayer\n",
    "import warnings\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating1 = []\n",
    "pos_list = []\n",
    "for i in os.listdir(\"train/pos/\"):\n",
    "    rating1.append(i[-6:-4])\n",
    "    ss = open(str(\"train/pos/\"+i) , encoding='utf-8')\n",
    "    pos_list.append(ss.read())\n",
    "    ss.close()\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in os.listdir(\"train/neg/\"):\n",
    "    rating1.append(i[-6:-4])\n",
    "    ss = open(str(\"train/neg/\"+i) , encoding='utf-8')\n",
    "    pos_list.append(ss.read())\n",
    "    ss.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating =[]\n",
    "for i in rating1:\n",
    "    if i[0]=='_':\n",
    "        rating.append(int(i[1]))\n",
    "    else:\n",
    "        rating.append(int(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['Text'] = [i for i in pos_list]\n",
    "dataframe['rating'] =[i for i in rating] \n",
    "dataframe = dataframe.sample(frac=1)\n",
    "dataframe = dataframe[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5000 entries, 18550 to 15586\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Text    5000 non-null   object\n",
      " 1   rating  5000 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 117.2+ KB\n"
     ]
    }
   ],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                          Text  \\\n",
      "18550  This is one of the worst movies I've seen in a long time. Not just the story, but the acting is shockingly bad. The dialog sounds like someone reading the news.<br /><br />This is rated as comedy/...   \n",
      "14304  \"A young woman unwittingly becomes part of a kidnapping plot involving the son of a movie producer she is babysitting. The kidnappers happen to be former business partners of the son's father and ...   \n",
      "10941  It's been 19 years since Gordon Gekko used \"Wall Street\" to let us know that greed is good. Now, Michael Douglas takes the GG persona and morphs it into a Secret Service agent, Pete Garrison. Gues...   \n",
      "4343   A series of random, seemingly insignificant thefts at her sister's boarding house has Miss Lemon quite agitated. A ring, light bulbs, a rucksack, a lighter, a stethoscope, a shoe  there seems to ...   \n",
      "24228  This film is the worst excuse for a motion picture I have EVER seen. To begin, I'd like to say the the front cover of this film is by all means misleading, if you think you are about to see a trul...   \n",
      "...                                                                                                                                                                                                        ...   \n",
      "12357  Lily Mars, a smalltown girl living in Indiana, dreams of making it big on Broadway and her aspirations are given a lift when successful Broadway producer John Thornway returns to his hometown for ...   \n",
      "12268  I give this movie 7 out of 10 because the villains were interesting in their roles and the unknown batwoman creates an interesting \"guess who\" game. The movie, however, needs more Robin in it. He ...   \n",
      "526    I was amazingly impressed by this movie. It contained fundamental elements of depression, grief, loneliness, despair, hope, dreams and companionship. It wasn't merely about a genius musician who h...   \n",
      "2703   This is a good movie, although people unfamiliar with the Modesty Blaise comics and books may find it a little slow and lacking in action. For the Modesty fan, the movie will be very enjoyable, pa...   \n",
      "15586  Well, not yet, at least.<br /><br />It's not listed in the worst 100...<br /><br />So let's all team up, and put it in it's rightful place.<br /><br />This is truly a bad movie. (And I liked Ishta...   \n",
      "\n",
      "       rating  \n",
      "18550       2  \n",
      "14304       4  \n",
      "10941       7  \n",
      "4343        7  \n",
      "24228       1  \n",
      "...       ...  \n",
      "12357       7  \n",
      "12268       7  \n",
      "526         9  \n",
      "2703        8  \n",
      "15586       1  \n",
      "\n",
      "[5000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Aditya\n",
      "[nltk_data]     Parihar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "data = dataframe\n",
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "def text_cleaner(text,num):\n",
    "    newString = text.lower()\n",
    "    newString = BeautifulSoup(newString, \"lxml\").text\n",
    "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
    "    newString = re.sub('\"','', newString)\n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
    "    newString = re.sub('[m]{2,}', 'mm', newString)\n",
    "    if(num==0):\n",
    "        tokens = [w for w in newString.split() if not w in stop_words]\n",
    "    else:\n",
    "        tokens=newString.split()\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>1:                                                 #removing short word\n",
    "            long_words.append(i)   \n",
    "    return (\" \".join(long_words)).strip()\n",
    "\n",
    "cleaned_text = []\n",
    "for t in data['Text']:\n",
    "    cleaned_text.append(text_cleaner(t,0))\n",
    "\n",
    "data['cleaned_text']=cleaned_text\n",
    "data.replace('', np.nan, inplace=True)\n",
    "data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_word_count = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in data['cleaned_text']:\n",
    "      text_word_count.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'text':text_word_count})\n",
    "\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_len=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8692\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "for i in data['cleaned_text']:\n",
    "    if(len(i.split())<=200):\n",
    "        cnt=cnt+1\n",
    "print(cnt/len(data['cleaned_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5000 entries, 18550 to 15586\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Text          5000 non-null   object\n",
      " 1   rating        5000 non-null   int64 \n",
      " 2   cleaned_text  5000 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 156.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text =np.array(data['cleaned_text'])\n",
    "rating_before = np.array(data['rating'])\n",
    "\n",
    "short_text=[]\n",
    "rating = []\n",
    "for i in range(len(cleaned_text)):\n",
    "    if(len(cleaned_text[i].split())<=max_text_len):\n",
    "        short_text.append(cleaned_text[i])\n",
    "        rating.append(rating_before[i])\n",
    "        \n",
    "df=pd.DataFrame({'text':short_text,'rating':rating})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                      text  \\\n",
      "0  one worst movies seen long time story acting shockingly bad dialog sounds like someone reading news rated comedy drama romance things little action really comedy drama went cinema see feel sorry w...   \n",
      "1  young woman unwittingly becomes part kidnapping plot involving son movie producer babysitting kidnappers happen former business partners son father looking exact revenge babysitter must bide time ...   \n",
      "2  years since gordon gekko used wall street let us know greed good michael douglas takes gg persona morphs secret service agent pete garrison guess works solid political thriller kept guessing detai...   \n",
      "3  series random seemingly insignificant thefts sister boarding house miss lemon quite agitated ring light bulbs rucksack lighter stethoscope shoe seems rhyme reason miss lemon asks employer great be...   \n",
      "4  film worst excuse motion picture ever seen begin would like say front cover film means misleading think see truly scary horror film monster clown soooo wrong fact killers face even slightly resemb...   \n",
      "\n",
      "   rating  \n",
      "0       2  \n",
      "1       4  \n",
      "2       7  \n",
      "3       7  \n",
      "4       1  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vecs(glove_file):\n",
    "    f = open(glove_file, encoding=\"utf-8\", errors='ignore')\n",
    "    words = set()\n",
    "    word_to_vec_map = {}\n",
    "        \n",
    "    for line in f:\n",
    "        line = line.strip().split()\n",
    "        curr_word = line[0]\n",
    "        words.add(curr_word)\n",
    "        word_to_vec_map[curr_word] = np.asarray(line[1:], dtype=np.float64)\n",
    "            \n",
    "    return words, word_to_vec_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, word_to_vec_map = read_glove_vecs('glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = list(word_to_vec_map.keys())\n",
    "word_to_index = {}\n",
    "for key,value in enumerate(w):\n",
    "    word_to_index[value] = key\n",
    "    \n",
    "index_to_word = {}\n",
    "for key, value in enumerate(w):\n",
    "    index_to_word[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29794"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index['cucumber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLen = len(max(df['text'], key=len).split())\n",
    "maxLen = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, maxLen):\n",
    "    \"\"\"\n",
    "    Converts an array of sentences (strings) into an array of indices corresponding to words in the sentences.\n",
    "    The output shape should be such that it can be given to `Embedding()` (described in Figure 4). \n",
    "    \n",
    "    Arguments:\n",
    "    X -- array of sentences (strings), of shape (m, 1)\n",
    "    word_to_index -- a dictionary containing the each word mapped to its index\n",
    "    max_len -- maximum number of words in a sentence. You can assume every sentence in X is no longer than this. \n",
    "    \n",
    "    Returns:\n",
    "    X_indices -- array of indices corresponding to words in the sentences from X, of shape (m, max_len)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0]                                   # number of training examples\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Initialize X_indices as a numpy matrix of zeros and the correct shape (≈ 1 line)\n",
    "    X_indices = np.zeros((m, maxLen))\n",
    "    convert = X.values\n",
    "    for i in range(m):                               # loop over training examples\n",
    "        \n",
    "        # Convert the ith training sentence in lower case and split is into words. You should get a list of words.\n",
    "        sentence_words = convert[i].split()\n",
    "        # Initialize j to 0\n",
    "        j = 0\n",
    "        \n",
    "        #Loop over the words of sentence_words\n",
    "        for w in sentence_words:\n",
    "            # Set the (i,j)th entry of X_indices to the index of the correct word.\n",
    "            if w not in word_to_index.keys():\n",
    "                X_indices[i, j] = word_to_index['unk']\n",
    "            else:\n",
    "                X_indices[i, j] = word_to_index[w]\n",
    "            # Increment j to j + 1\n",
    "            j += 1\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    \"\"\"\n",
    "    Creates a Keras Embedding() layer and loads in pre-trained GloVe 50-dimensional vectors.\n",
    "    \n",
    "    Arguments:\n",
    "    word_to_vec_map -- dictionary mapping words to their GloVe vector representation.\n",
    "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
    "\n",
    "    Returns:\n",
    "    embedding_layer -- pretrained layer Keras instance\n",
    "    \"\"\"\n",
    "    \n",
    "    vocab_len = len(word_to_index) + 1                  # adding 1 to fit Keras embedding (requirement)\n",
    "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]      # define dimensionality of your GloVe word vectors (= 50)\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Initialize the embedding matrix as a numpy array of zeros of shape (vocab_len, dimensions of word vectors = emb_dim)\n",
    "    emb_matrix = np.zeros((vocab_len, emb_dim))\n",
    "    \n",
    "    # Set each row \"index\" of the embedding matrix to be the word vector representation of the \"index\"th word of the vocabulary\n",
    "    for word, index in word_to_index.items():\n",
    "        emb_matrix[index, :] = word_to_vec_map[word]\n",
    "\n",
    "    # Define Keras embedding layer with the correct output/input sizes, make it trainable. Use Embedding(...). Make sure to set trainable=False. \n",
    "    embedding_layer = Embedding(vocab_len, emb_dim, trainable=False)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Build the embedding layer, it is required before setting the weights of the embedding layer. Do not modify the \"None\".\n",
    "    embedding_layer.build((None,))\n",
    "    \n",
    "    # Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 200, 50)           20000050  \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional [(None, 200, 600), (None, 842400    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection [(None, 600), (None, 300) 2162400   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 4808      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 23,009,658\n",
      "Trainable params: 3,009,608\n",
      "Non-trainable params: 20,000,050\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import backend as K \n",
    "K.clear_session()\n",
    "\n",
    "latent_dim = 300\n",
    "embedding_dim=100\n",
    "\n",
    "# Encoder\n",
    "sentence_indices = Input(shape=(max_text_len,), dtype='int32')\n",
    "\n",
    "#embedding layer\n",
    "embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "enc_emb =  embedding_layer(sentence_indices)   \n",
    "#encoder lstm 1\n",
    "encoder_lstm1_f = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_lstm1_r = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4,go_backwards=True)## ##\n",
    "\n",
    "encoder_bi1 = Bidirectional(encoder_lstm1_f, backward_layer=encoder_lstm1_r,)\n",
    "encoder_output1, state_h1, state_c1, state_r_h1, state_r_h1 = encoder_bi1(enc_emb)\n",
    "\n",
    "#encoder lstm 2\n",
    "encoder_lstm2_r = LSTM(latent_dim,return_sequences=False,return_state=True,dropout=0.4,recurrent_dropout=0.4,go_backwards=True)##\n",
    "encoder_lstm2_f = LSTM(latent_dim,return_sequences=False,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "\n",
    "encoder_bi2 = Bidirectional(encoder_lstm2_f, backward_layer=encoder_lstm2_r)\n",
    "encoder_output2, state_h2, state_c2, state_r_h2, state_r_h2 = encoder_bi2(encoder_output1)\n",
    "\n",
    "\n",
    "X = Dense(8)(encoder_output2)\n",
    "# Add a softmax activation\n",
    "X = Activation('softmax')(X)\n",
    "\n",
    "# Define the model \n",
    "model = Model(inputs = sentence_indices, outputs = X)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4302, 8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df['text']\n",
    "y = df['rating'].values\n",
    "y = y.reshape(-1, 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01, random_state=42)\n",
    "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "y_train_indices = encoder.fit_transform(y_train).toarray()\n",
    "y_train_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.0363 WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "67/67 [==============================] - 3018s 45s/step - loss: 2.0363\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.9126  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "67/67 [==============================] - 4224s 63s/step - loss: 1.9126\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.8738  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "67/67 [==============================] - 4854s 72s/step - loss: 1.8738\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.8434  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "67/67 [==============================] - 5303s 79s/step - loss: 1.8434\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.8142  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "67/67 [==============================] - 5586s 83s/step - loss: 1.8142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1359a7adef0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_indices, y_train_indices, epochs = 5, callbacks=[es], batch_size = 65, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 18s 9s/step - loss: 1.8764\n"
     ]
    }
   ],
   "source": [
    "X_test_indices = sentences_to_indices(X_test, word_to_index, maxLen)\n",
    "y_test_indices = encoder.transform(y_test).toarray()\n",
    "loss = model.evaluate(X_test_indices, y_test_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5559388  0.16976665 0.06649095 0.07718341 0.0197537  0.02155652\n",
      "  0.03107242 0.05823762]\n",
      " [0.6098227  0.1859893  0.07386318 0.0597468  0.01586052 0.01477927\n",
      "  0.01187235 0.02806597]\n",
      " [0.0370956  0.00883074 0.02103702 0.00983977 0.10762917 0.18701491\n",
      "  0.40993604 0.21861674]\n",
      " [0.47060266 0.22381692 0.07665522 0.1150685  0.03073544 0.02413154\n",
      "  0.02183566 0.03715402]\n",
      " [0.67802423 0.17175888 0.0534675  0.047564   0.01251741 0.0112949\n",
      "  0.00870264 0.01667054]\n",
      " [0.02700722 0.01075184 0.02702479 0.01291374 0.11306521 0.19699924\n",
      "  0.29303563 0.31920233]\n",
      " [0.79472893 0.10561618 0.03303007 0.02847411 0.0072486  0.00833125\n",
      "  0.00709363 0.0154772 ]\n",
      " [0.02793846 0.01276185 0.03018825 0.0231184  0.10480225 0.20231329\n",
      "  0.37085626 0.2280213 ]\n",
      " [0.02110369 0.00719579 0.02230016 0.01886307 0.13567    0.24317107\n",
      "  0.346021   0.20567523]\n",
      " [0.85719967 0.08310685 0.01930315 0.01541695 0.00416447 0.00479003\n",
      "  0.0041357  0.01188315]\n",
      " [0.03260829 0.02143937 0.04457455 0.0455599  0.22971441 0.29144412\n",
      "  0.23372543 0.10093389]\n",
      " [0.521926   0.12352433 0.0554512  0.10944256 0.03312115 0.03366042\n",
      "  0.04124125 0.08163305]\n",
      " [0.8559329  0.08524175 0.01953938 0.01617772 0.00420058 0.00489084\n",
      "  0.00346727 0.01054953]\n",
      " [0.05823716 0.02516884 0.04034831 0.03027269 0.07909105 0.156805\n",
      "  0.24906735 0.36100963]\n",
      " [0.05060404 0.01273606 0.02532428 0.02105875 0.10398249 0.182225\n",
      "  0.3331756  0.27089378]\n",
      " [0.01929485 0.00815986 0.02267782 0.01788365 0.15198804 0.2732673\n",
      "  0.33046722 0.17626119]\n",
      " [0.03117779 0.00878196 0.02047747 0.01388495 0.09527653 0.16615108\n",
      "  0.34128222 0.32296795]\n",
      " [0.04285163 0.01805106 0.0324349  0.02618008 0.09408956 0.24138926\n",
      "  0.33799905 0.20700446]\n",
      " [0.0416961  0.01057032 0.02760067 0.01561925 0.10968513 0.144243\n",
      "  0.4156046  0.23498091]\n",
      " [0.85932547 0.08201125 0.02006172 0.01544066 0.00418986 0.00440597\n",
      "  0.00387901 0.01068612]\n",
      " [0.59559584 0.12128464 0.05283226 0.05394714 0.02326819 0.03017099\n",
      "  0.04297747 0.07992344]\n",
      " [0.83463895 0.0990926  0.02881414 0.01592121 0.00436344 0.00488602\n",
      "  0.00315727 0.00912655]\n",
      " [0.06255627 0.02563539 0.03806794 0.04233789 0.13278742 0.23655921\n",
      "  0.26819694 0.19385894]\n",
      " [0.0882634  0.03587341 0.06719451 0.04817182 0.09444442 0.15972713\n",
      "  0.24132098 0.2650043 ]\n",
      " [0.03677888 0.00964332 0.02109573 0.0114345  0.06343499 0.14922336\n",
      "  0.29848745 0.40990183]\n",
      " [0.3744843  0.20098747 0.12114861 0.17143217 0.03997845 0.03126916\n",
      "  0.02462309 0.03607673]\n",
      " [0.03861694 0.01551103 0.03193501 0.02730649 0.14878231 0.26163676\n",
      "  0.30476785 0.1714436 ]\n",
      " [0.0269506  0.00710136 0.01917503 0.00951503 0.08078703 0.16209744\n",
      "  0.34617636 0.3481972 ]\n",
      " [0.04346163 0.01259114 0.02490852 0.0188957  0.14191076 0.20336603\n",
      "  0.34628782 0.20857844]\n",
      " [0.6111838  0.08991408 0.03710323 0.03746596 0.02189306 0.04114635\n",
      "  0.04786243 0.11343104]\n",
      " [0.0535781  0.02690614 0.04591733 0.05097824 0.14458247 0.24578902\n",
      "  0.25426224 0.17798647]\n",
      " [0.45216995 0.17261153 0.09289855 0.11760555 0.04358428 0.04129934\n",
      "  0.03310822 0.04672259]\n",
      " [0.01856541 0.00514736 0.0161429  0.00751676 0.09755421 0.1982478\n",
      "  0.40565285 0.25117272]\n",
      " [0.47563645 0.14280419 0.08338382 0.09105002 0.03331941 0.03533122\n",
      "  0.04755743 0.09091745]\n",
      " [0.03152047 0.01084509 0.02510969 0.0201993  0.10165759 0.20015503\n",
      "  0.35445392 0.25605887]\n",
      " [0.52285784 0.08036451 0.03832789 0.02588322 0.02419103 0.05182833\n",
      "  0.08663131 0.16991594]\n",
      " [0.1436657  0.14146622 0.15881938 0.2808053  0.09884576 0.06528669\n",
      "  0.03563576 0.07547513]\n",
      " [0.19605011 0.05766239 0.05888678 0.03832612 0.06742471 0.11775498\n",
      "  0.17953001 0.2843649 ]\n",
      " [0.7621722  0.12331693 0.03104006 0.03466509 0.00929111 0.01098153\n",
      "  0.00810436 0.02042863]\n",
      " [0.6897528  0.12645611 0.04212454 0.0516571  0.01354413 0.01475699\n",
      "  0.01928304 0.04242539]\n",
      " [0.4885087  0.14890788 0.088181   0.10564803 0.03371973 0.02819954\n",
      "  0.03002571 0.07680939]\n",
      " [0.8511969  0.08194605 0.0187689  0.01774502 0.00467245 0.00545181\n",
      "  0.00524012 0.01497885]\n",
      " [0.04777906 0.01330788 0.02532503 0.01293716 0.06894646 0.1160677\n",
      "  0.28726497 0.42837182]\n",
      " [0.7861481  0.12314108 0.0293281  0.03095407 0.00602554 0.00484448\n",
      "  0.00541431 0.01414426]]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test_indices)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0.\n",
      " 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.metrics import categorical_accuracy\n",
    "metric = categorical_accuracy(y_test_indices, pred)\n",
    "print(metric.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
